version: '3'

services:
  fastllm-cuda:
    build:
      context: .
      dockerfile: Dockerfile.cuda
    image: fastllm:cuda
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - ./config:/app/config
    environment:
      - CUDA_VISIBLE_DEVICES=all
    command: ["--mode", "server"]

  fastllm-m1:
    build:
      context: .
      dockerfile: Dockerfile.m1
    ports:
      - "8000:8000"
      - "8001:8001"
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    environment:
        - PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.
    restart: unless-stopped
    
    volumes:
      - ./config:/app/config

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'

volumes:
  prometheus-data: